{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "init_time: 200903162117\n    task: flvl\n    output_dim: 3\n    model_type: GRU\n    bi_dir: False\n    device: cuda:0\n    data_root: /home/nvme/vladimir/corsmal/features\n    batch_size: 64\n    input_dim: 128\n    hidden_dim: 512\n    n_layers: 5\n    drop_p: 0.0\n    num_epochs: 25\n    seed: 1337\n{'train': [1, 2, 4, 5, 7, 8], 'valid': [3, 6, 9], 'test': [10, 11, 12]}\n(train @ 1): L: 1.118631; A: 0.388158; R: 0.388158; P: 0.384786; F1: 0.386154\n(valid @ 1): L: 1.033358; A: 0.451754; R: 0.451754; P: 0.406327; F1: 0.381783\n(train @ 2): L: 1.017749; A: 0.432018; R: 0.432018; P: 0.381862; F1: 0.362292\n(valid @ 2): L: 0.981211; A: 0.456140; R: 0.456140; P: 0.412731; F1: 0.384962\n(train @ 3): L: 0.978148; A: 0.458333; R: 0.458333; P: 0.542096; F1: 0.429868\n(valid @ 3): L: 0.969354; A: 0.526316; R: 0.526316; P: 0.481203; F1: 0.471108\n(train @ 4): L: 0.982257; A: 0.508772; R: 0.508772; P: 0.539121; F1: 0.481134\n(valid @ 4): L: 0.892660; A: 0.421053; R: 0.421053; P: 0.387517; F1: 0.257040\n(train @ 5): L: 0.946895; A: 0.475877; R: 0.475877; P: 0.490042; F1: 0.457508\n(valid @ 5): L: 0.809918; A: 0.565789; R: 0.565789; P: 0.578543; F1: 0.552227\n(train @ 6): L: 0.911168; A: 0.510965; R: 0.510965; P: 0.546591; F1: 0.515154\n(valid @ 6): L: 0.901395; A: 0.482456; R: 0.482456; P: 0.456510; F1: 0.404045\n(train @ 7): L: 0.890753; A: 0.491228; R: 0.491228; P: 0.532263; F1: 0.456946\n(valid @ 7): L: 0.786507; A: 0.644737; R: 0.644737; P: 0.646850; F1: 0.642827\n(train @ 8): L: 0.807559; A: 0.603070; R: 0.603070; P: 0.626527; F1: 0.602806\n(valid @ 8): L: 0.710252; A: 0.649123; R: 0.649123; P: 0.648762; F1: 0.646169\n(train @ 9): L: 0.731619; A: 0.657895; R: 0.657895; P: 0.684982; F1: 0.653194\n(valid @ 9): L: 0.784023; A: 0.635965; R: 0.635965; P: 0.670018; F1: 0.636680\n(train @ 10): L: 0.706904; A: 0.651316; R: 0.651316; P: 0.653969; F1: 0.648408\n(valid @ 10): L: 0.727566; A: 0.653509; R: 0.653509; P: 0.682797; F1: 0.655221\n(train @ 11): L: 0.750752; A: 0.662281; R: 0.662281; P: 0.682733; F1: 0.659204\n(valid @ 11): L: 0.675299; A: 0.666667; R: 0.666667; P: 0.675202; F1: 0.667288\n(train @ 12): L: 0.666221; A: 0.712719; R: 0.712719; P: 0.724871; F1: 0.710419\n(valid @ 12): L: 0.632944; A: 0.701754; R: 0.701754; P: 0.709852; F1: 0.704463\n(train @ 13): L: 0.623047; A: 0.688596; R: 0.688596; P: 0.720465; F1: 0.680361\n(valid @ 13): L: 0.821740; A: 0.627193; R: 0.627193; P: 0.634203; F1: 0.612591\n(train @ 14): L: 0.676382; A: 0.662281; R: 0.662281; P: 0.670749; F1: 0.649865\n(valid @ 14): L: 0.647569; A: 0.635965; R: 0.635965; P: 0.713450; F1: 0.585075\n(train @ 15): L: 0.583887; A: 0.710526; R: 0.710526; P: 0.718314; F1: 0.706538\n(valid @ 15): L: 0.717036; A: 0.657895; R: 0.657895; P: 0.676421; F1: 0.649034\n(train @ 16): L: 0.611387; A: 0.692982; R: 0.692982; P: 0.723718; F1: 0.672200\n(valid @ 16): L: 0.624834; A: 0.653509; R: 0.653509; P: 0.663113; F1: 0.653888\n(train @ 17): L: 0.608845; A: 0.714912; R: 0.714912; P: 0.719502; F1: 0.714330\n(valid @ 17): L: 0.589334; A: 0.697368; R: 0.697368; P: 0.708627; F1: 0.689262\n(train @ 18): L: 0.604350; A: 0.728070; R: 0.728070; P: 0.734053; F1: 0.722978\n(valid @ 18): L: 0.570472; A: 0.710526; R: 0.710526; P: 0.716564; F1: 0.710881\n(train @ 19): L: 0.528573; A: 0.752193; R: 0.752193; P: 0.772927; F1: 0.747839\n(valid @ 19): L: 0.597797; A: 0.684211; R: 0.684211; P: 0.686887; F1: 0.683941\n(train @ 20): L: 0.540910; A: 0.736842; R: 0.736842; P: 0.737061; F1: 0.736757\n(valid @ 20): L: 0.544489; A: 0.719298; R: 0.719298; P: 0.722555; F1: 0.716148\n(train @ 21): L: 0.513056; A: 0.745614; R: 0.745614; P: 0.750134; F1: 0.743960\n(valid @ 21): L: 0.543392; A: 0.723684; R: 0.723684; P: 0.737301; F1: 0.721270\n(train @ 22): L: 0.502658; A: 0.765351; R: 0.765351; P: 0.777961; F1: 0.763583\n(valid @ 22): L: 0.532367; A: 0.714912; R: 0.714912; P: 0.736780; F1: 0.704532\n(train @ 23): L: 0.529665; A: 0.723684; R: 0.723684; P: 0.744079; F1: 0.712528\n(valid @ 23): L: 0.621721; A: 0.653509; R: 0.653509; P: 0.658942; F1: 0.641144\n(train @ 24): L: 0.473815; A: 0.767544; R: 0.767544; P: 0.772576; F1: 0.765101\n(valid @ 24): L: 0.532264; A: 0.723684; R: 0.723684; P: 0.738218; F1: 0.717233\n(train @ 25): L: 0.528747; A: 0.752193; R: 0.752193; P: 0.758930; F1: 0.750209\n(valid @ 25): L: 0.548295; A: 0.728070; R: 0.728070; P: 0.744365; F1: 0.720725\nBest val Metric 0.721270 @ 21\n\n{'train': [1, 3, 4, 6, 7, 9], 'valid': [2, 5, 8], 'test': [10, 11, 12]}\n(train @ 1): L: 1.124828; A: 0.379386; R: 0.379386; P: 0.376003; F1: 0.370564\n(valid @ 1): L: 1.009583; A: 0.482456; R: 0.482456; P: 0.401419; F1: 0.419012\n(train @ 2): L: 1.042205; A: 0.427632; R: 0.427632; P: 0.359788; F1: 0.382463\n(valid @ 2): L: 0.964426; A: 0.473684; R: 0.473684; P: 0.455928; F1: 0.381907\n(train @ 3): L: 1.028550; A: 0.460526; R: 0.460526; P: 0.417985; F1: 0.390773\n(valid @ 3): L: 1.005153; A: 0.421053; R: 0.421053; P: 0.385637; F1: 0.295354\n(train @ 4): L: 1.007071; A: 0.418860; R: 0.418860; P: 0.405824; F1: 0.395197\n(valid @ 4): L: 0.845019; A: 0.421053; R: 0.421053; P: 0.385637; F1: 0.295354\n(train @ 5): L: 0.962084; A: 0.460526; R: 0.460526; P: 0.412325; F1: 0.409557\n(valid @ 5): L: 0.790173; A: 0.600877; R: 0.600877; P: 0.625979; F1: 0.591997\n(train @ 6): L: 0.929850; A: 0.495614; R: 0.495614; P: 0.537281; F1: 0.503159\n(valid @ 6): L: 0.861480; A: 0.521930; R: 0.521930; P: 0.430309; F1: 0.467836\n(train @ 7): L: 0.884904; A: 0.484649; R: 0.484649; P: 0.569824; F1: 0.440190\n(valid @ 7): L: 0.760100; A: 0.692982; R: 0.692982; P: 0.702044; F1: 0.695110\n(train @ 8): L: 0.808766; A: 0.618421; R: 0.618421; P: 0.621011; F1: 0.619074\n(valid @ 8): L: 0.703423; A: 0.644737; R: 0.644737; P: 0.741675; F1: 0.602349\n(train @ 9): L: 0.826242; A: 0.537281; R: 0.537281; P: 0.551916; F1: 0.528698\n(valid @ 9): L: 0.729155; A: 0.671053; R: 0.671053; P: 0.694474; F1: 0.674377\n(train @ 10): L: 0.750090; A: 0.620614; R: 0.620614; P: 0.622839; F1: 0.616900\n(valid @ 10): L: 0.665556; A: 0.679825; R: 0.679825; P: 0.689748; F1: 0.679465\n(train @ 11): L: 0.763752; A: 0.592105; R: 0.592105; P: 0.601851; F1: 0.587179\n(valid @ 11): L: 0.590557; A: 0.750000; R: 0.750000; P: 0.754366; F1: 0.750746\n(train @ 12): L: 0.644051; A: 0.666667; R: 0.666667; P: 0.667924; F1: 0.667260\n(valid @ 12): L: 0.655799; A: 0.649123; R: 0.649123; P: 0.742629; F1: 0.597199\n(train @ 13): L: 0.632471; A: 0.697368; R: 0.697368; P: 0.713787; F1: 0.689672\n(valid @ 13): L: 0.552720; A: 0.710526; R: 0.710526; P: 0.726974; F1: 0.702256\n(train @ 14): L: 0.626558; A: 0.675439; R: 0.675439; P: 0.671467; F1: 0.671734\n(valid @ 14): L: 0.495373; A: 0.776316; R: 0.776316; P: 0.793269; F1: 0.771803\n(train @ 15): L: 0.546643; A: 0.730263; R: 0.730263; P: 0.733356; F1: 0.730516\n(valid @ 15): L: 0.522509; A: 0.750000; R: 0.750000; P: 0.807535; F1: 0.733676\n(train @ 16): L: 0.554357; A: 0.721491; R: 0.721491; P: 0.739092; F1: 0.713564\n(valid @ 16): L: 0.492554; A: 0.785088; R: 0.785088; P: 0.785648; F1: 0.784942\n(train @ 17): L: 0.543810; A: 0.730263; R: 0.730263; P: 0.748979; F1: 0.725479\n(valid @ 17): L: 0.527660; A: 0.754386; R: 0.754386; P: 0.780921; F1: 0.744673\n(train @ 18): L: 0.627364; A: 0.743421; R: 0.743421; P: 0.744073; F1: 0.739779\n(valid @ 18): L: 0.505475; A: 0.758772; R: 0.758772; P: 0.773090; F1: 0.755719\n(train @ 19): L: 0.541302; A: 0.732456; R: 0.732456; P: 0.751557; F1: 0.729671\n(valid @ 19): L: 0.584424; A: 0.701754; R: 0.701754; P: 0.702796; F1: 0.694511\n(train @ 20): L: 0.571384; A: 0.697368; R: 0.697368; P: 0.694297; F1: 0.693005\n(valid @ 20): L: 0.526979; A: 0.741228; R: 0.741228; P: 0.792388; F1: 0.724733\n(train @ 21): L: 0.550513; A: 0.732456; R: 0.732456; P: 0.747705; F1: 0.731855\n(valid @ 21): L: 0.497725; A: 0.771930; R: 0.771930; P: 0.790554; F1: 0.765676\n(train @ 22): L: 0.574253; A: 0.719298; R: 0.719298; P: 0.728637; F1: 0.710978\n(valid @ 22): L: 0.476307; A: 0.771930; R: 0.771930; P: 0.784795; F1: 0.768310\n(train @ 23): L: 0.513041; A: 0.723684; R: 0.723684; P: 0.754856; F1: 0.711996\n(valid @ 23): L: 0.485908; A: 0.767544; R: 0.767544; P: 0.773550; F1: 0.765231\n(train @ 24): L: 0.505718; A: 0.754386; R: 0.754386; P: 0.756648; F1: 0.752880\n(valid @ 24): L: 0.523894; A: 0.741228; R: 0.741228; P: 0.805036; F1: 0.721584\n(train @ 25): L: 0.530083; A: 0.754386; R: 0.754386; P: 0.766986; F1: 0.752382\n(valid @ 25): L: 0.483576; A: 0.767544; R: 0.767544; P: 0.782417; F1: 0.764613\nBest val Metric 0.784942 @ 16\n\n{'train': [2, 3, 5, 6, 8, 9], 'valid': [1, 4, 7], 'test': [10, 11, 12]}\n(train @ 1): L: 1.099835; A: 0.410088; R: 0.410088; P: 0.407215; F1: 0.407321\n(valid @ 1): L: 1.025184; A: 0.421053; R: 0.421053; P: 0.177285; F1: 0.249513\n(train @ 2): L: 1.003454; A: 0.453947; R: 0.453947; P: 0.382070; F1: 0.414901\n(valid @ 2): L: 1.050273; A: 0.464912; R: 0.464912; P: 0.533551; F1: 0.482568\n(train @ 3): L: 0.989258; A: 0.447368; R: 0.447368; P: 0.472549; F1: 0.427774\n(valid @ 3): L: 0.992099; A: 0.403509; R: 0.403509; P: 0.449184; F1: 0.324038\n(train @ 4): L: 0.900470; A: 0.451754; R: 0.451754; P: 0.512878; F1: 0.430750\n(valid @ 4): L: 1.033831; A: 0.482456; R: 0.482456; P: 0.544409; F1: 0.492021\n(train @ 5): L: 0.884470; A: 0.515351; R: 0.515351; P: 0.552579; F1: 0.483070\n(valid @ 5): L: 0.975628; A: 0.464912; R: 0.464912; P: 0.468359; F1: 0.459711\n(train @ 6): L: 0.801825; A: 0.567982; R: 0.567982; P: 0.577092; F1: 0.563042\n(valid @ 6): L: 0.899189; A: 0.552632; R: 0.552632; P: 0.589419; F1: 0.537474\n(train @ 7): L: 0.772273; A: 0.616228; R: 0.616228; P: 0.650174; F1: 0.605995\n(valid @ 7): L: 0.857969; A: 0.578947; R: 0.578947; P: 0.576943; F1: 0.574736\n(train @ 8): L: 0.730170; A: 0.646930; R: 0.646930; P: 0.647303; F1: 0.645875\n(valid @ 8): L: 0.907287; A: 0.535088; R: 0.535088; P: 0.637358; F1: 0.511776\n(train @ 9): L: 0.799796; A: 0.576754; R: 0.576754; P: 0.577454; F1: 0.575707\n(valid @ 9): L: 0.676871; A: 0.706140; R: 0.706140; P: 0.733940; F1: 0.703071\n(train @ 10): L: 0.635235; A: 0.688596; R: 0.688596; P: 0.685998; F1: 0.684369\n(valid @ 10): L: 0.691018; A: 0.627193; R: 0.627193; P: 0.645097; F1: 0.630504\n(train @ 11): L: 0.568296; A: 0.692982; R: 0.692982; P: 0.692866; F1: 0.690594\n(valid @ 11): L: 0.623082; A: 0.684211; R: 0.684211; P: 0.696262; F1: 0.688006\n(train @ 12): L: 0.539022; A: 0.714912; R: 0.714912; P: 0.713750; F1: 0.712933\n(valid @ 12): L: 0.622049; A: 0.640351; R: 0.640351; P: 0.732119; F1: 0.600320\n(train @ 13): L: 0.524236; A: 0.723684; R: 0.723684; P: 0.743684; F1: 0.715364\n(valid @ 13): L: 0.603434; A: 0.671053; R: 0.671053; P: 0.672984; F1: 0.668769\n(train @ 14): L: 0.518360; A: 0.730263; R: 0.730263; P: 0.738254; F1: 0.726838\n(valid @ 14): L: 0.571004; A: 0.736842; R: 0.736842; P: 0.741574; F1: 0.736254\n(train @ 15): L: 0.496370; A: 0.739035; R: 0.739035; P: 0.741366; F1: 0.738096\n(valid @ 15): L: 0.601658; A: 0.662281; R: 0.662281; P: 0.733953; F1: 0.625366\n(train @ 16): L: 0.508704; A: 0.712719; R: 0.712719; P: 0.715842; F1: 0.711071\n(valid @ 16): L: 0.563756; A: 0.736842; R: 0.736842; P: 0.743816; F1: 0.734370\n(train @ 17): L: 0.502801; A: 0.747807; R: 0.747807; P: 0.754320; F1: 0.745444\n(valid @ 17): L: 0.577900; A: 0.763158; R: 0.763158; P: 0.777517; F1: 0.759300\n(train @ 18): L: 0.505316; A: 0.743421; R: 0.743421; P: 0.744431; F1: 0.743029\n(valid @ 18): L: 0.583801; A: 0.719298; R: 0.719298; P: 0.725970; F1: 0.713757\n(train @ 19): L: 0.490453; A: 0.736842; R: 0.736842; P: 0.736911; F1: 0.736814\n(valid @ 19): L: 0.562051; A: 0.719298; R: 0.719298; P: 0.719456; F1: 0.719315\n(train @ 20): L: 0.515391; A: 0.725877; R: 0.725877; P: 0.727656; F1: 0.725055\n(valid @ 20): L: 0.554018; A: 0.758772; R: 0.758772; P: 0.780497; F1: 0.752844\n(train @ 21): L: 0.491392; A: 0.754386; R: 0.754386; P: 0.761538; F1: 0.751957\n(valid @ 21): L: 0.586369; A: 0.697368; R: 0.697368; P: 0.696275; F1: 0.696756\n(train @ 22): L: 0.488898; A: 0.758772; R: 0.758772; P: 0.759994; F1: 0.757959\n(valid @ 22): L: 0.853781; A: 0.662281; R: 0.662281; P: 0.684696; F1: 0.663073\n(train @ 23): L: 0.507868; A: 0.732456; R: 0.732456; P: 0.733842; F1: 0.731712\n(valid @ 23): L: 0.944876; A: 0.644737; R: 0.644737; P: 0.698262; F1: 0.641450\n(train @ 24): L: 0.553236; A: 0.725877; R: 0.725877; P: 0.725824; F1: 0.725847\n(valid @ 24): L: 0.577111; A: 0.710526; R: 0.710526; P: 0.740421; F1: 0.698290\n(train @ 25): L: 0.508598; A: 0.741228; R: 0.741228; P: 0.753739; F1: 0.737362\n(valid @ 25): L: 0.572156; A: 0.728070; R: 0.728070; P: 0.736978; F1: 0.727296\nBest val Metric 0.759300 @ 17\n\nAverage of Best Metrics on Each Valid Set: 0.755171, 200903162117_200903163219\n"
    }
   ],
   "source": [
    "# Reproduce the best experiment\n",
    "# Average of Best Metrics on Each Valid Set: 0.755171, 200903162117\n",
    "import argparse\n",
    "from main import Config, run_kfold\n",
    "from time import localtime, strftime\n",
    "\n",
    "exp_name = 200903162117\n",
    "cfg = Config()\n",
    "cfg.load_from(path=f'./predictions/{exp_name}/cfg.txt')\n",
    "# replacing the time with the old_time + current_time such that there is no collision\n",
    "cfg.init_time = f'{cfg.init_time}_{strftime(\"%y%m%d%H%M%S\", localtime())}'\n",
    "run_kfold(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'train': [1, 2, 4, 5, 7, 8], 'valid': [3, 6, 9], 'test': [10, 11, 12]}\n(train @ 1): L: 1.118631; A: 0.388158; R: 0.388158; P: 0.384786; F1: 0.386154\n(valid @ 1): L: 1.033358; A: 0.451754; R: 0.451754; P: 0.406327; F1: 0.381783\n(train @ 2): L: 1.017749; A: 0.432018; R: 0.432018; P: 0.381862; F1: 0.362292\n(valid @ 2): L: 0.981211; A: 0.456140; R: 0.456140; P: 0.412731; F1: 0.384962\n(train @ 3): L: 0.978148; A: 0.458333; R: 0.458333; P: 0.542096; F1: 0.429868\n(valid @ 3): L: 0.969354; A: 0.526316; R: 0.526316; P: 0.481203; F1: 0.471108\n(train @ 4): L: 0.982257; A: 0.508772; R: 0.508772; P: 0.539121; F1: 0.481134\n(valid @ 4): L: 0.892660; A: 0.421053; R: 0.421053; P: 0.387517; F1: 0.257040\n(train @ 5): L: 0.946895; A: 0.475877; R: 0.475877; P: 0.490042; F1: 0.457508\n(valid @ 5): L: 0.809918; A: 0.565789; R: 0.565789; P: 0.578543; F1: 0.552227\n(train @ 6): L: 0.911168; A: 0.510965; R: 0.510965; P: 0.546591; F1: 0.515154\n(valid @ 6): L: 0.901395; A: 0.482456; R: 0.482456; P: 0.456510; F1: 0.404045\n(train @ 7): L: 0.890753; A: 0.491228; R: 0.491228; P: 0.532263; F1: 0.456946\n(valid @ 7): L: 0.786507; A: 0.644737; R: 0.644737; P: 0.646850; F1: 0.642827\n(train @ 8): L: 0.807559; A: 0.603070; R: 0.603070; P: 0.626527; F1: 0.602806\n(valid @ 8): L: 0.710252; A: 0.649123; R: 0.649123; P: 0.648762; F1: 0.646169\n(train @ 9): L: 0.731619; A: 0.657895; R: 0.657895; P: 0.684982; F1: 0.653194\n(valid @ 9): L: 0.784023; A: 0.635965; R: 0.635965; P: 0.670018; F1: 0.636680\n(train @ 10): L: 0.706904; A: 0.651316; R: 0.651316; P: 0.653969; F1: 0.648408\n(valid @ 10): L: 0.727566; A: 0.653509; R: 0.653509; P: 0.682797; F1: 0.655221\n(train @ 11): L: 0.750752; A: 0.662281; R: 0.662281; P: 0.682733; F1: 0.659204\n(valid @ 11): L: 0.675299; A: 0.666667; R: 0.666667; P: 0.675202; F1: 0.667288\n(train @ 12): L: 0.666221; A: 0.712719; R: 0.712719; P: 0.724871; F1: 0.710419\n(valid @ 12): L: 0.632944; A: 0.701754; R: 0.701754; P: 0.709852; F1: 0.704463\n(train @ 13): L: 0.623047; A: 0.688596; R: 0.688596; P: 0.720465; F1: 0.680361\n(valid @ 13): L: 0.821740; A: 0.627193; R: 0.627193; P: 0.634203; F1: 0.612591\n(train @ 14): L: 0.676382; A: 0.662281; R: 0.662281; P: 0.670749; F1: 0.649865\n(valid @ 14): L: 0.647569; A: 0.635965; R: 0.635965; P: 0.713450; F1: 0.585075\n(train @ 15): L: 0.583887; A: 0.710526; R: 0.710526; P: 0.718314; F1: 0.706538\n(valid @ 15): L: 0.717036; A: 0.657895; R: 0.657895; P: 0.676421; F1: 0.649034\n(train @ 16): L: 0.611387; A: 0.692982; R: 0.692982; P: 0.723718; F1: 0.672200\n(valid @ 16): L: 0.624834; A: 0.653509; R: 0.653509; P: 0.663113; F1: 0.653888\n(train @ 17): L: 0.608845; A: 0.714912; R: 0.714912; P: 0.719502; F1: 0.714330\n(valid @ 17): L: 0.589334; A: 0.697368; R: 0.697368; P: 0.708627; F1: 0.689262\n(train @ 18): L: 0.604350; A: 0.728070; R: 0.728070; P: 0.734053; F1: 0.722978\n(valid @ 18): L: 0.570472; A: 0.710526; R: 0.710526; P: 0.716564; F1: 0.710881\n(train @ 19): L: 0.528573; A: 0.752193; R: 0.752193; P: 0.772927; F1: 0.747839\n(valid @ 19): L: 0.597797; A: 0.684211; R: 0.684211; P: 0.686887; F1: 0.683941\n(train @ 20): L: 0.540910; A: 0.736842; R: 0.736842; P: 0.737061; F1: 0.736757\n(valid @ 20): L: 0.544489; A: 0.719298; R: 0.719298; P: 0.722555; F1: 0.716148\n(train @ 21): L: 0.513056; A: 0.745614; R: 0.745614; P: 0.750134; F1: 0.743960\n(valid @ 21): L: 0.543392; A: 0.723684; R: 0.723684; P: 0.737301; F1: 0.721270\n(train @ 22): L: 0.502658; A: 0.765351; R: 0.765351; P: 0.777961; F1: 0.763583\n(valid @ 22): L: 0.532367; A: 0.714912; R: 0.714912; P: 0.736780; F1: 0.704532\n(train @ 23): L: 0.529665; A: 0.723684; R: 0.723684; P: 0.744079; F1: 0.712528\n(valid @ 23): L: 0.621721; A: 0.653509; R: 0.653509; P: 0.658942; F1: 0.641144\n(train @ 24): L: 0.473815; A: 0.767544; R: 0.767544; P: 0.772576; F1: 0.765101\n(valid @ 24): L: 0.532264; A: 0.723684; R: 0.723684; P: 0.738218; F1: 0.717233\n(train @ 25): L: 0.528747; A: 0.752193; R: 0.752193; P: 0.758930; F1: 0.750209\n(valid @ 25): L: 0.548295; A: 0.728070; R: 0.728070; P: 0.744365; F1: 0.720725\nBest val Metric 0.721270 @ 21\n\n{'train': [1, 3, 4, 6, 7, 9], 'valid': [2, 5, 8], 'test': [10, 11, 12]}\n(train @ 1): L: 1.124828; A: 0.379386; R: 0.379386; P: 0.376003; F1: 0.370564\n(valid @ 1): L: 1.009583; A: 0.482456; R: 0.482456; P: 0.401419; F1: 0.419012\n(train @ 2): L: 1.042205; A: 0.427632; R: 0.427632; P: 0.359788; F1: 0.382463\n(valid @ 2): L: 0.964426; A: 0.473684; R: 0.473684; P: 0.455928; F1: 0.381907\n(train @ 3): L: 1.028550; A: 0.460526; R: 0.460526; P: 0.417985; F1: 0.390773\n(valid @ 3): L: 1.005153; A: 0.421053; R: 0.421053; P: 0.385637; F1: 0.295354\n(train @ 4): L: 1.007071; A: 0.418860; R: 0.418860; P: 0.405824; F1: 0.395197\n(valid @ 4): L: 0.845019; A: 0.421053; R: 0.421053; P: 0.385637; F1: 0.295354\n(train @ 5): L: 0.962084; A: 0.460526; R: 0.460526; P: 0.412325; F1: 0.409557\n(valid @ 5): L: 0.790173; A: 0.600877; R: 0.600877; P: 0.625979; F1: 0.591997\n(train @ 6): L: 0.929850; A: 0.495614; R: 0.495614; P: 0.537281; F1: 0.503159\n(valid @ 6): L: 0.861480; A: 0.521930; R: 0.521930; P: 0.430309; F1: 0.467836\n(train @ 7): L: 0.884904; A: 0.484649; R: 0.484649; P: 0.569824; F1: 0.440190\n(valid @ 7): L: 0.760100; A: 0.692982; R: 0.692982; P: 0.702044; F1: 0.695110\n(train @ 8): L: 0.808766; A: 0.618421; R: 0.618421; P: 0.621011; F1: 0.619074\n(valid @ 8): L: 0.703423; A: 0.644737; R: 0.644737; P: 0.741675; F1: 0.602349\n(train @ 9): L: 0.826242; A: 0.537281; R: 0.537281; P: 0.551916; F1: 0.528698\n(valid @ 9): L: 0.729155; A: 0.671053; R: 0.671053; P: 0.694474; F1: 0.674377\n(train @ 10): L: 0.750090; A: 0.620614; R: 0.620614; P: 0.622839; F1: 0.616900\n(valid @ 10): L: 0.665556; A: 0.679825; R: 0.679825; P: 0.689748; F1: 0.679465\n(train @ 11): L: 0.763752; A: 0.592105; R: 0.592105; P: 0.601851; F1: 0.587179\n(valid @ 11): L: 0.590557; A: 0.750000; R: 0.750000; P: 0.754366; F1: 0.750746\n(train @ 12): L: 0.644051; A: 0.666667; R: 0.666667; P: 0.667924; F1: 0.667260\n(valid @ 12): L: 0.655799; A: 0.649123; R: 0.649123; P: 0.742629; F1: 0.597199\n(train @ 13): L: 0.632471; A: 0.697368; R: 0.697368; P: 0.713787; F1: 0.689672\n(valid @ 13): L: 0.552720; A: 0.710526; R: 0.710526; P: 0.726974; F1: 0.702256\n(train @ 14): L: 0.626558; A: 0.675439; R: 0.675439; P: 0.671467; F1: 0.671734\n(valid @ 14): L: 0.495373; A: 0.776316; R: 0.776316; P: 0.793269; F1: 0.771803\n(train @ 15): L: 0.546643; A: 0.730263; R: 0.730263; P: 0.733356; F1: 0.730516\n(valid @ 15): L: 0.522509; A: 0.750000; R: 0.750000; P: 0.807535; F1: 0.733676\n(train @ 16): L: 0.554357; A: 0.721491; R: 0.721491; P: 0.739092; F1: 0.713564\n(valid @ 16): L: 0.492554; A: 0.785088; R: 0.785088; P: 0.785648; F1: 0.784942\n(train @ 17): L: 0.543810; A: 0.730263; R: 0.730263; P: 0.748979; F1: 0.725479\n(valid @ 17): L: 0.527660; A: 0.754386; R: 0.754386; P: 0.780921; F1: 0.744673\n(train @ 18): L: 0.627364; A: 0.743421; R: 0.743421; P: 0.744073; F1: 0.739779\n(valid @ 18): L: 0.505475; A: 0.758772; R: 0.758772; P: 0.773090; F1: 0.755719\n(train @ 19): L: 0.541302; A: 0.732456; R: 0.732456; P: 0.751557; F1: 0.729671\n(valid @ 19): L: 0.584424; A: 0.701754; R: 0.701754; P: 0.702796; F1: 0.694511\n(train @ 20): L: 0.571384; A: 0.697368; R: 0.697368; P: 0.694297; F1: 0.693005\n(valid @ 20): L: 0.526979; A: 0.741228; R: 0.741228; P: 0.792388; F1: 0.724733\n(train @ 21): L: 0.550513; A: 0.732456; R: 0.732456; P: 0.747705; F1: 0.731855\n(valid @ 21): L: 0.497725; A: 0.771930; R: 0.771930; P: 0.790554; F1: 0.765676\n(train @ 22): L: 0.574253; A: 0.719298; R: 0.719298; P: 0.728637; F1: 0.710978\n(valid @ 22): L: 0.476307; A: 0.771930; R: 0.771930; P: 0.784795; F1: 0.768310\n(train @ 23): L: 0.513041; A: 0.723684; R: 0.723684; P: 0.754856; F1: 0.711996\n(valid @ 23): L: 0.485908; A: 0.767544; R: 0.767544; P: 0.773550; F1: 0.765231\n(train @ 24): L: 0.505718; A: 0.754386; R: 0.754386; P: 0.756648; F1: 0.752880\n(valid @ 24): L: 0.523894; A: 0.741228; R: 0.741228; P: 0.805036; F1: 0.721584\n(train @ 25): L: 0.530083; A: 0.754386; R: 0.754386; P: 0.766986; F1: 0.752382\n(valid @ 25): L: 0.483576; A: 0.767544; R: 0.767544; P: 0.782417; F1: 0.764613\nBest val Metric 0.784942 @ 16\n\n{'train': [2, 3, 5, 6, 8, 9], 'valid': [1, 4, 7], 'test': [10, 11, 12]}\n(train @ 1): L: 1.099835; A: 0.410088; R: 0.410088; P: 0.407215; F1: 0.407321\n(valid @ 1): L: 1.025184; A: 0.421053; R: 0.421053; P: 0.177285; F1: 0.249513\n(train @ 2): L: 1.003454; A: 0.453947; R: 0.453947; P: 0.382070; F1: 0.414901\n(valid @ 2): L: 1.050273; A: 0.464912; R: 0.464912; P: 0.533551; F1: 0.482568\n(train @ 3): L: 0.989258; A: 0.447368; R: 0.447368; P: 0.472549; F1: 0.427774\n(valid @ 3): L: 0.992099; A: 0.403509; R: 0.403509; P: 0.449184; F1: 0.324038\n(train @ 4): L: 0.900470; A: 0.451754; R: 0.451754; P: 0.512878; F1: 0.430750\n(valid @ 4): L: 1.033831; A: 0.482456; R: 0.482456; P: 0.544409; F1: 0.492021\n(train @ 5): L: 0.884470; A: 0.515351; R: 0.515351; P: 0.552579; F1: 0.483070\n(valid @ 5): L: 0.975628; A: 0.464912; R: 0.464912; P: 0.468359; F1: 0.459711\n(train @ 6): L: 0.801825; A: 0.567982; R: 0.567982; P: 0.577092; F1: 0.563042\n(valid @ 6): L: 0.899189; A: 0.552632; R: 0.552632; P: 0.589419; F1: 0.537474\n(train @ 7): L: 0.772273; A: 0.616228; R: 0.616228; P: 0.650174; F1: 0.605995\n(valid @ 7): L: 0.857969; A: 0.578947; R: 0.578947; P: 0.576943; F1: 0.574736\n(train @ 8): L: 0.730170; A: 0.646930; R: 0.646930; P: 0.647303; F1: 0.645875\n(valid @ 8): L: 0.907287; A: 0.535088; R: 0.535088; P: 0.637358; F1: 0.511776\n(train @ 9): L: 0.799796; A: 0.576754; R: 0.576754; P: 0.577454; F1: 0.575707\n(valid @ 9): L: 0.676871; A: 0.706140; R: 0.706140; P: 0.733940; F1: 0.703071\n(train @ 10): L: 0.635235; A: 0.688596; R: 0.688596; P: 0.685998; F1: 0.684369\n(valid @ 10): L: 0.691018; A: 0.627193; R: 0.627193; P: 0.645097; F1: 0.630504\n(train @ 11): L: 0.568296; A: 0.692982; R: 0.692982; P: 0.692866; F1: 0.690594\n(valid @ 11): L: 0.623082; A: 0.684211; R: 0.684211; P: 0.696262; F1: 0.688006\n(train @ 12): L: 0.539022; A: 0.714912; R: 0.714912; P: 0.713750; F1: 0.712933\n(valid @ 12): L: 0.622049; A: 0.640351; R: 0.640351; P: 0.732119; F1: 0.600320\n(train @ 13): L: 0.524236; A: 0.723684; R: 0.723684; P: 0.743684; F1: 0.715364\n(valid @ 13): L: 0.603434; A: 0.671053; R: 0.671053; P: 0.672984; F1: 0.668769\n(train @ 14): L: 0.518360; A: 0.730263; R: 0.730263; P: 0.738254; F1: 0.726838\n(valid @ 14): L: 0.571004; A: 0.736842; R: 0.736842; P: 0.741574; F1: 0.736254\n(train @ 15): L: 0.496370; A: 0.739035; R: 0.739035; P: 0.741366; F1: 0.738096\n(valid @ 15): L: 0.601658; A: 0.662281; R: 0.662281; P: 0.733953; F1: 0.625366\n(train @ 16): L: 0.508704; A: 0.712719; R: 0.712719; P: 0.715842; F1: 0.711071\n(valid @ 16): L: 0.563756; A: 0.736842; R: 0.736842; P: 0.743816; F1: 0.734370\n(train @ 17): L: 0.502801; A: 0.747807; R: 0.747807; P: 0.754320; F1: 0.745444\n(valid @ 17): L: 0.577900; A: 0.763158; R: 0.763158; P: 0.777517; F1: 0.759300\n(train @ 18): L: 0.505316; A: 0.743421; R: 0.743421; P: 0.744431; F1: 0.743029\n(valid @ 18): L: 0.583801; A: 0.719298; R: 0.719298; P: 0.725970; F1: 0.713757\n(train @ 19): L: 0.490453; A: 0.736842; R: 0.736842; P: 0.736911; F1: 0.736814\n(valid @ 19): L: 0.562051; A: 0.719298; R: 0.719298; P: 0.719456; F1: 0.719315\n(train @ 20): L: 0.515391; A: 0.725877; R: 0.725877; P: 0.727656; F1: 0.725055\n(valid @ 20): L: 0.554018; A: 0.758772; R: 0.758772; P: 0.780497; F1: 0.752844\n(train @ 21): L: 0.491392; A: 0.754386; R: 0.754386; P: 0.761538; F1: 0.751957\n(valid @ 21): L: 0.586369; A: 0.697368; R: 0.697368; P: 0.696275; F1: 0.696756\n(train @ 22): L: 0.488898; A: 0.758772; R: 0.758772; P: 0.759994; F1: 0.757959\n(valid @ 22): L: 0.853781; A: 0.662281; R: 0.662281; P: 0.684696; F1: 0.663073\n(train @ 23): L: 0.507868; A: 0.732456; R: 0.732456; P: 0.733842; F1: 0.731712\n(valid @ 23): L: 0.944876; A: 0.644737; R: 0.644737; P: 0.698262; F1: 0.641450\n(train @ 24): L: 0.553236; A: 0.725877; R: 0.725877; P: 0.725824; F1: 0.725847\n(valid @ 24): L: 0.577111; A: 0.710526; R: 0.710526; P: 0.740421; F1: 0.698290\n(train @ 25): L: 0.508598; A: 0.741228; R: 0.741228; P: 0.753739; F1: 0.737362\n(valid @ 25): L: 0.572156; A: 0.728070; R: 0.728070; P: 0.736978; F1: 0.727296\nBest val Metric 0.759300 @ 17\n\nAverage of Best Metrics on Each Valid Set: 0.755171, 200903162117\n"
    }
   ],
   "source": [
    "# Experiment with other parameters\n",
    "import argparse\n",
    "from main import Config, run_kfold\n",
    "\n",
    "cfg = Config()\n",
    "cfg.assign_variable('task', 'flvl')\n",
    "cfg.assign_variable('output_dim', 3)\n",
    "cfg.assign_variable('model_type', 'GRU')\n",
    "cfg.assign_variable('bi_dir', False)\n",
    "cfg.assign_variable('device', 'cuda:0')\n",
    "cfg.assign_variable('data_root', '/home/nvme/vladimir/corsmal/features')\n",
    "cfg.assign_variable('batch_size', 64)\n",
    "cfg.assign_variable('input_dim', 128)\n",
    "cfg.assign_variable('hidden_dim', 512)\n",
    "cfg.assign_variable('n_layers', 5)\n",
    "cfg.assign_variable('drop_p', 0.0) # results will be irreproducible\n",
    "cfg.assign_variable('num_epochs', 25)\n",
    "cfg.assign_variable('seed', 1337)\n",
    "\n",
    "run_kfold(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}